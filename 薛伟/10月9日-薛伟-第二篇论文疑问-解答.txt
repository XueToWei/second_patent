1、整个算法流程，需要一个手绘流程图
答：需要等邱龙同学手绘流程图后得到算法流程

2、主要对创新点进行介绍
答：主要包括四部分：
	1）Mosaic-8数据增强。即采用8张图片随机裁剪、随机排列、随机缩放，然后组合成一张图片，以此来增加样本的数据量，同时合理引入一些随机噪声，增强网络模型对图像中小目标样本的区分力，提升模型的泛化力。
	2）在YOLOv5骨干网络的基础上对原始输入图片增加一个4倍下采样的过程，将低层特征图与高层特征图进行信息融合，即将特征金字塔网络与路径聚合网络(PAN, Path Aggregation Network)相结合，特征金字塔网络自顶向下传递深层次语义特征，路径聚合网络自底向上传递目标的位置信息，通过顶向下和自底向上的特征信息融合有利于模型更好的学习到特征，增强模型对小目标和遮挡目标的敏感度。
	3）选择CIoU替代GIoU作为目标框回归的损失函数。
	4）目标框回归公式的修改，请见原论文的公式9~13


3、【3.4  目标框回归】最后一段中，请解释这句话：在最小的特征图上，由于其【感受野】最大，故应该用其来检测大目标，所以大尺度的特征图应该应用小尺寸的先验框，小尺寸的特征图应该应用大尺度的特征图来进行预测框的回归。
答：在典型CNN结构中，FC层每个输出节点的值都依赖FC层所有输入，而CONV层每个输出节点的值仅依赖CONV层输入的一个区域，这个区域之外的其他输入值都不会影响输出值，该区域就是感受野。

4、【3  改进YOLOv5算法】第一段中，对此句存疑：通过新增尺寸为输入图像尺寸四分之一的特征图来提升对小目标特征的挖掘，采用多尺度反馈以引入全局上下文信息来提升对图像中小目标的识别能力
答：算法的输入图片尺寸大小为416×416，在本文的改进后的特征提取模型中(见图6)得到了4个尺度的特征，即小、中、大尺寸，以及新尺度特征的尺寸大小为104×104，正好是输入尺寸的四分之一，即【通过新增尺寸为输入图像尺寸四分之一的特征图来提升对小目标特征的挖掘】。

5、介绍【目标框回归原理】
答：目标框回归的目的就是要寻找某种映射关系，使得候选目标框(Region Proposal)的映射无限接近于真实目标框(Ground Truth)。对真实目标框的预测，通过预测相对位置的方法预测出目标框相对于坐上角的相对坐标。先验框与预测框的关系如图 10所示，其中，虚线框表示先验框，实线框表示预测框。预测框通过先验框平移缩放得到。将原始图片根据特征图尺寸划分成个网格单元，每个网格单元会预测3个预测框，每个预测框包含4个坐标信息和1个置信度信息。当真实框中某个目标中心坐标落在某个网格中时，就由该网格预测这个目标。

6、【3.4】一节第一段的第四行【坐上角】错别字修改
答：这个是修改建议，不是问题